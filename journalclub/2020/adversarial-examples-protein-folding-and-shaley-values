# Journal Club, episode 8

Kyle: AlphaFold

George dives into his [blog post](https://dataskeptic.com/blog/journalclub/2020/tree-shap-and-alcohol-consumption) experimenting with [Scott Lundberg's SHAP library](https://github.com/slundberg/shap). By training an XGBoost model on a dataset about academic attainment and alcohol consumption can we develop a global interpretation of the underlying relationships? 

Lan leads the discussion of the paper [Adversarial Examples Are Not Bugs, They Are Features](https://arxiv.org/abs/1905.02175) by Ilyas and colleagues. This papers proposes a new perspective on adversarial susceptibility of machine learning models by teasing apart the 'robust' and the 'non-robust' features in a dataset. The authors summarizes the key take away message as "Adversarial vulnerability is a direct result of the models’ sensitivity to well-generalizing, ‘non-robust’ features in the data." 
