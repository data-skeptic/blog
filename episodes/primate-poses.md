# Primate Poses

Richard Vogg, a PhD student at the University of GÃ¶ttingen, Germany, joins us in this episode. His research borders on studying groups of primate behavior. Richard particularly trains the deep learning models to understand how lemurs learn socially.

He started by discussing the observed social behavior of lemurs. He shared how he and his colleagues collect data from the wild to study lemurs. He also discussed how computer vision has been applied to solve motion-tracking problems. He mainly discussed using YOLO models for object detection in monkeys and their limitations.

Richard shared the challenge of setting up experiments in the wild versus in the lab. Other than object detection, he shared valuable technologies for studying primates. He discussed the challenge of unlabelled data and strategies to label data efficiently.

Richard also discussed the tools and libraries he used to develop his models. He shared how computer scientists and biologists can enhance the adoption of these models in the coming year. Given the low amount of labeled data on lemurs, Richard discussed how models were developed to identify lemurs. He discussed the tradeoffs between R and Python. 


## Resources

[R-Vlogg Blog](https://r-vogg-blog.netlify.app/)

[MacaquePose](https://paperswithcode.com/dataset/macaquepose)


## Follow our guest

[Twitter/X](https://x.com/richard_vogg?lang=en)
