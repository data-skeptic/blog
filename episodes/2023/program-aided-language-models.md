# Program-aided Language Models

We are joined by Aman Madaan and Shuyan Zhou. They are both PhD students at the Language Technology Institute at Carnegie Mellon University. They join us to discuss their latest published paper, [PAL: Program-aided Language Models](https://reasonwithpal.com/).

Aman and Shuyan started by sharing how the application of LLMs has evolved. They talked about the performance of LLMs on arithmetic tasks in contrast to coding tasks. Aman introduced their PAL model and how it helps LLMs improve at arithmetic tasks. He shared examples of the tasks PAL was tested on. Shuyan discussed how PAL’s performance was evaluated using [Big Bench hard](https://github.com/suzgunmirac/BIG-Bench-Hard) tasks.

They discussed the kind of mistakes LLMs tend to make and how the PAL’s model circumvents these limitations. They also discussed how these developments in LLMS can improve kids learning. 

Rounding up, Amen discussed the [CoCoGen project](https://github.com/reasoning-machines/CoCoGen), a project that enables NLP tasks to be converted to graphs. Shuyan and Aman shared her next research steps. 

Follow Shuyan on Twitter [@shuyanzhxyc](https://twitter.com/shuyanzhxyc). Follow Aman on [@aman_madaan](https://twitter.com/aman_madaan).

Further reading includes [this mentioned paper](https://arxiv.org/abs/2308.07921), which solves high-school math problems using text (chain of thought) and code (PaL).

