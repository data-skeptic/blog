# Uncontrollable AI Risks

We are joined by Darren McKee, a Policy Advisor and the host of Reality Check — a critical thinking podcast. Darren gave a background about himself and how he got into the AI space.

Darren shared his thoughts on AGI's achievements in the coming years. He defined AGI and discussed how to differentiate an AGI system. He also shared whether AI needs consciousness to be AGI. 

Darren discussed his worry about AI surpassing human understanding of the universe and potentially causing harm to humanity. He also shared examples of how AI is already used for nefarious purposes. He explored whether AI possesses inherently evil intentions and gave his thoughts on regulating AI.

Darren reflected on the future prospects of AI and the hope for what lies ahead. Follow Darren on Twitter [@dbcmckee](https://twitter.com/dbcmckee).

Darren’s Book: [Uncontrollable: The Threat of Artificial Superintelligence and the Race to Save the World](https://www.amazon.ca/Uncontrollable-Threat-Artificial-Superintelligence-World/dp/B0CNNYKVH1/ref=zg_bs_g_387230011_sccl_1/141-4202109-0375516?psc=1).