# Graph Text

On the show today, we are joined by Jianan Zhao, a Computer Science student at Mila and the University of Montreal. His research focus is on graph databases and natural language processing. He joins us to discuss how to use graphs with LLMs efficiently.

Jianan started by sharing the overlap between graph databases and natural language processing. He explained what graph foundational models are and how they are trained. He talked about the performance of LLMs when they are passed with graph texts.

Jianan discussed a strategy to get graph texts from graph data. He discussed the advantages of using his technique to generate a graph text over existing approaches, such as using XMLs. Jianan also discussed how to effectively convert a large graph database, such as the OSM data. He also discussed how to measure the effectiveness of his framework.

Jianan talked about the future of graph texts. He also spoke about the possibility of having LLMs trained for graph-related data. Follow Jianan on Twitter [@AndyJiananZhao](https://twitter.com/AndyJiananZhao). You can learn more about his work on his [homepage](https://andyjzhao.github.io/) or [GitHub account](https://github.com/AndyJZhao?tab=repositories).