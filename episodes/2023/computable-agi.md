# Computable AGI

On today’s show, we are joined by Michael Timothy Bennett, a Ph.D. student at the Australian National University. Michael’s research is centered around Artificial General Intelligence (AGI), specifically the mathematical formalism of AGIs. He joins us to discuss findings from his study, [Computable Artificial General Intelligence](https://arxiv.org/abs/2205.10513).

Michael started by explaining what got him into his research. He discussed the problem of AIXI being subjective depending on the Turing machine used. He explained what AIXI is and how it is helpful in AI safety research. He introduced the concept of pan-computationalism: the idea that everything is a computational system. He, however, discussed how AIXI is incomputable.


He also discussed alternative approaches to engineering general intelligence, and of using weakness rather than simplicity (AIXI uses simplicity) to decide which models of an agent’s environment are most likely to hold true.

Michael discussed why weakness is a better approach. He described his results comparing weakness and simplicity for deciding between models, and what this implies. In his discussion, he also explained why generalization is a better description of intelligence than “the ability to satisfy goals”, citing François Chollet’s paper, [On the Measure of Intelligence](https://arxiv.org/abs/1911.01547).

Michael discussed his experiments involving a computer predicting the relationships between a set of 8-bit strings. He shared his thoughts on how his approach would behave at scale. You can learn more about Michael’s work on his [website](https://michaeltimothybennett.com/) or follow him on Twitter [@MiTiBennett](https://twitter.com/MiTiBennett).