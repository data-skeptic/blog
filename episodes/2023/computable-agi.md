# Computable AGI

On today’s show, we are joined by Michael Timothy Bennett, a Ph.D. student at the Australian National University. Michael’s research is centered around Artificial General Intelligence (AGI), specifically the mathematical formalism of AGIs. He joins us to discuss findings from his study, [Computable Artificial General Intelligence](https://arxiv.org/abs/2205.10513).

Michael started by explaining what got him into his research. He discussed the problem of AIXI being subjective depending on the Turing machine used. He explained what AIXI is and how it is helpful in AI safety research. He introduced the concept of pan-computationalism: the idea that everything is a computational system. He, however, discussed how AIXI is incomputable.

Michael explained why AIXI being incomputable is a problem. He explained the effect of using AIXI approximations rather than its optimal computation. He also discussed alternative approaches — simplicity, description length, and weakness — necessary to arrive at practical AIXI approximations. 

Michael discussed why weakness is a better approach for computing practical AIXI. In his discussion, he explained why generalization is a better measure of intelligence, citing François Chollet's paper, [On the Measure of Intelligence](https://arxiv.org/abs/1911.01547). He also shared the result of using the weakness approach for AIXI computation.

Michael discussed his experiments involving a computer predicting the relationships between a set of 8-bit strings. He shared his thoughts on how his approach would behave at scale. You can learn more about Michael’s work on his [website](https://michaeltimothybennett.com/) or follow him on Twitter [@MiTiBennett](https://twitter.com/MiTiBennett).