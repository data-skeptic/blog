# Emergent Deception in LLMs

On today’s show, we are joined by Thilo Hagendorff, a Research Group Leader of Ethics of Generative AI at the University of Stuttgart. He joins us to discuss his research, [Deception Abilities Emerged in Large Language Models](https://arxiv.org/abs/2307.16513).

Thilo discussed how machine psychology is useful in machine learning tasks. He shared examples of cognitive tasks that LLMs have improved at solving. He shared his thoughts on whether there’s a ceiling to the tasks ML can solve.

Thilo defined deception and discussed how he studied deception in LLMs experimentally. He shared the experiments he used to evaluate LLM’s deception abilities. He also shared how LLMs compare to humans in cognitive reflective tasks and deception tasks.

Thilo explained why LLMs can develop deception abilities. He also discussed how these deceptive abilities can be mitigated. Rounding up, he discussed his future research. You can learn more about Thilo’s work on his [website](https://www.thilo-hagendorff.info/).