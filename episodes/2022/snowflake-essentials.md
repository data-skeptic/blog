# Snowflake Essentials

Managing your database hardware comes with its risks. For example, if your hardware goes down due to high data volume or data migrations, your entire production site goes down. Apart from the cost of downtime, you irrecoverably lose records of crucial analytics. But cloud computing comes as an easy solution. And Snowflakes is a unique, fast, and cost-effective cloud-based solution. 

In today's episode, we interviewed [Frank Bell](https://twitter.com/frank8993), the author of the book [Snowflake Essentials: Getting Started with Big Data in the Cloud](https://www.amazon.com/Snowflake-Essentials-Getting-Started-Cloud/dp/148427315X). Frank got into the internet and data space quite early. In the mid-1990s, he got a scholarship to the Airforce, where he worked with Oracle 4. He managed the programs that handled air battle planning using the Oracle Database in that capacity. 

Frank began today’s discussion by highlighting what differentiates Snowflake from all the competition and why Snowflake is preferably called a Data Cloud service. 

He further discussed how you could seamlessly use Snowflake's Data Cloud for big data computations. How that it gives you the SQL-like experience with no custom code. If you want a safe and easy way to test-run your big data side projects, you may want to consider Snowflake's free trial package.

Frank then spoke about how Snowflake started in 2012 and was able to get early adopters in a short span. They did this by proffering unique solutions to long-standing problems from scratch. Many of which he spoke about. He went on to discuss how the founders of Snowflake have tracked progress over the years, publishing their findings and future goals in the [Sigmoid Paper](https://www.snowflake.com/resource/sigmod-2016-paper-snowflake-elastic-data-warehouse/).  

You may also be thinking. Say I want to get started with Snowflake. How would Snowflake load and consume data from my data sources? Well, Frank touched on that as well. He discussed how you could use [AWS Snowball](https://aws.amazon.com/snowball/?whats-new-cards.sort-by=item.additionalFields.postDateTime&whats-new-cards.sort-order=desc) to connect your data sources to Snowflake and run data science workflows with sizes to the tune of TBs in a matter of minutes. In addition, he extensively discussed the advanced features that make Snowflake stand out of the park as a Data Cloud service.

If you are not sure how to get data for your projects, there might be a solution. Frank went on to talk about [Snowflake Solutions](https://snowflakesolutions.net/) - a data marketplace, to get quality data for your data science projects.

He ended by talking about his book; who the book is for, and how you can transition to using the Snowflake ecosystem seamlessly with the book. You can grab your copy on [Amazon](https://www.amazon.com/Snowflake-Essentials-Getting-Started-Cloud/dp/148427315X). 